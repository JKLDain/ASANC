{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mel=np.load('all_mel.npy', mmap_mode=None, allow_pickle=True, fix_imports=True, encoding='ASCII')\n",
    "output_label=np.load('label_data.npy', mmap_mode=None, allow_pickle=True, fix_imports=True, encoding='ASCII')\n",
    "output_label= output_label.reshape(-1)\n",
    "output_label=np.array(output_label,dtype=np.int64);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mel = input_mel\n",
    "label = output_label\n",
    "\n",
    "# shuffle = False\n",
    "\n",
    "mel_train, mel_test, label_train, label_test = train_test_split(mel, \n",
    "                                                    label, \n",
    "                                                    test_size=0.25,                    \n",
    "                                                    random_state=123)\n",
    "\n",
    "mel_train = np.reshape(mel_train,(21290,1,101,101))\n",
    "mel_test = np.reshape(mel_test,(7097,1,101,101))\n",
    "\n",
    "X_train = torch.Tensor(mel_train);\n",
    "X_test = torch.Tensor(mel_test);\n",
    "y_train = torch.LongTensor(label_train);\n",
    "y_test = torch.LongTensor(label_test);\n",
    "\n",
    "ds_train = TensorDataset(X_train, y_train)\n",
    "ds_test = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dataset 함수 정의\n",
    "def create_datasets(batch_size):\n",
    "    # trainning set 중 validation 데이터로 사용할 비율\n",
    "    valid_size = 0.3\n",
    "\n",
    "    # torch.FloatTensor로 변환\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    # validation으로 사용할 trainning indices를 얻는다.\n",
    "    num_train = len(ds_train)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    # trainning, validation batch를 얻기 위한 sampler정의\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # load training data in batches\n",
    "    loader_train = torch.utils.data.DataLoader(ds_train,\n",
    "                                               batch_size=batch_size,\n",
    "                                               sampler=train_sampler,\n",
    "                                               num_workers=0)\n",
    "\n",
    "    # load validation data in batches\n",
    "    loader_valid = torch.utils.data.DataLoader(ds_train,\n",
    "                                               batch_size=batch_size,\n",
    "                                               sampler=valid_sampler,\n",
    "                                               num_workers=0)\n",
    "\n",
    "    # load test data in batches\n",
    "    loader_test = torch.utils.data.DataLoader(ds_test,\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_workers=0)\n",
    "\n",
    "    return loader_train, loader_valid, loader_test\n",
    "\n",
    "\n",
    "# CNN 모델 정의\n",
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout2d(0.2),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "\n",
    "    \n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout2d(0.2),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout2d(0.2),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "   \n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout2d(0.2),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        \n",
    "        # flatten\n",
    "        self.flatten=nn.Flatten()\n",
    "\n",
    "        # 전결합층 6x6x64 inputs -> 4 outputs\n",
    "        self.fc = torch.nn.Linear(6*6*64, 4, bias=True)\n",
    "        \n",
    "\n",
    "\n",
    "        # 전결합층 한정으로 가중치 초기화\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.flatten(out)   # 전결합층을 위해서 Flatten\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# overfitting 방지를 위한 EarlyStopping 정의\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
    "                            Default: 7\n",
    "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
    "                            Default: False\n",
    "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
    "                            Default: 0\n",
    "            path (str): checkpoint저장 경로\n",
    "                            Default: 'checkpoint.pt'\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "train_accus = []        \n",
    "valid_accus = []\n",
    "        \n",
    "# train 함수 정의\n",
    "def train_model(model, batch_size, patience, n_epochs):\n",
    "\n",
    "    # 모델이 학습되는 동안 trainning loss를 track\n",
    "    train_losses = []\n",
    "    # 모델이 학습되는 동안 validation loss를 track\n",
    "    valid_losses = []\n",
    "    # epoch당 average training loss를 track\n",
    "    avg_train_losses = []\n",
    "    # epoch당 average validation loss를 track\n",
    "    avg_valid_losses = []\n",
    "    \n",
    "    correct_train=0\n",
    "    correct_val = 0\n",
    "    total_train = 0\n",
    "    total_val = 0\n",
    "    # early_stopping object의 초기화\n",
    "    early_stopping = EarlyStopping(patience = patience, verbose = True)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        print(f\"======================[Epoch {epoch:2d}]======================\")\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train() # prep model for training\n",
    "        for batch, (data, targets) in enumerate(loader_train, 1):\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()    \n",
    "            # forward pass: 입력된 값을 모델로 전달하여 예측 출력 계산\n",
    "            outputs = model(data)\n",
    "            # calculate the loss\n",
    "            loss = loss_fn(outputs,targets.flatten())\n",
    "            # backward pass: 모델의 파라미터와 관련된 loss의 그래디언트 계산\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # record training loss\n",
    "            _, predicted = torch.max(outputs.data, 1)  # 확률이 가장 높은 레이블이 무엇인지 계산\n",
    "            correct_train += predicted.eq(targets.data.view_as(predicted)).sum()\n",
    "            total_train += targets.data.size(0)\n",
    "            train_losses.append(loss.item())\n",
    "            print(f'\\r {batch}/{len(loader_train)}', end='')\n",
    "\n",
    "        train_accu=100.*correct_train/total_train\n",
    "        train_accus.append(train_accu)    \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval() # prep model for evaluation\n",
    "        for data , targets in loader_valid :\n",
    "            # forward pass: 입력된 값을 모델로 전달하여 예측 출력 계산\n",
    "            outputs = model(data)\n",
    "            # calculate the loss\n",
    "            loss = loss_fn(outputs,targets.flatten())\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)  # 확률이 가장 높은 레이블이 무엇인지 계산\n",
    "            correct_val += predicted.eq(targets.data.view_as(predicted)).sum()\n",
    "            total_val += targets.data.size(0)\n",
    "            # record validation loss\n",
    "            valid_losses.append(loss.item())\n",
    "        valid_accu=100.*correct_val/total_val\n",
    "        valid_accus.append(valid_accu)    \n",
    "        # print 학습/검증 statistics\n",
    "        # epoch당 평균 loss 계산\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "\n",
    "        epoch_len = len(str(n_epochs))\n",
    "\n",
    "\n",
    "        print_msg = (f'epoch : [{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f}')\n",
    "\n",
    "        print(print_msg)\n",
    "\n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "\n",
    "        # early_stopping는 validation loss가 감소하였는지 확인이 필요하며,\n",
    "        # 만약 감소하였을경우 현제 모델을 checkpoint로 만든다.\n",
    "        early_stopping(valid_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "   # best model이 저장되어있는 last checkpoint를 로드한다.\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return  model, avg_train_losses, avg_valid_losses\n",
    "\n",
    "# CNN 모델 정의\n",
    "model = CNN()\n",
    "\n",
    "batch_size = 128\n",
    "n_epochs = 100\n",
    "learning_rate = 0.001\n",
    "criterion = torch.nn.CrossEntropyLoss()    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# dataset 만들기\n",
    "loader_train, loader_valid, loader_test = create_datasets(batch_size)\n",
    "\n",
    "# early stopping patience;\n",
    "# validation loss가 개선된 마지막 시간 이후로 얼마나 기다릴지 지정\n",
    "patience = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================[Epoch  1]======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayjo\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 117/117epoch : [  1/100] train_loss: 0.33124 valid_loss: 0.04544\n",
      "Validation loss decreased (inf --> 0.045444).  Saving model ...\n",
      "======================[Epoch  2]======================\n",
      " 117/117epoch : [  2/100] train_loss: 0.05170 valid_loss: 0.03568\n",
      "Validation loss decreased (0.045444 --> 0.035679).  Saving model ...\n",
      "======================[Epoch  3]======================\n",
      " 117/117epoch : [  3/100] train_loss: 0.04013 valid_loss: 0.03244\n",
      "Validation loss decreased (0.035679 --> 0.032436).  Saving model ...\n",
      "======================[Epoch  4]======================\n",
      " 117/117epoch : [  4/100] train_loss: 0.03900 valid_loss: 0.02716\n",
      "Validation loss decreased (0.032436 --> 0.027156).  Saving model ...\n",
      "======================[Epoch  5]======================\n",
      " 117/117epoch : [  5/100] train_loss: 0.03151 valid_loss: 0.02518\n",
      "Validation loss decreased (0.027156 --> 0.025176).  Saving model ...\n",
      "======================[Epoch  6]======================\n",
      " 117/117epoch : [  6/100] train_loss: 0.02916 valid_loss: 0.02820\n",
      "EarlyStopping counter: 1 out of 20\n",
      "======================[Epoch  7]======================\n",
      " 117/117epoch : [  7/100] train_loss: 0.02701 valid_loss: 0.03111\n",
      "EarlyStopping counter: 2 out of 20\n",
      "======================[Epoch  8]======================\n",
      " 117/117epoch : [  8/100] train_loss: 0.02807 valid_loss: 0.03644\n",
      "EarlyStopping counter: 3 out of 20\n",
      "======================[Epoch  9]======================\n",
      " 117/117epoch : [  9/100] train_loss: 0.02471 valid_loss: 0.03348\n",
      "EarlyStopping counter: 4 out of 20\n",
      "======================[Epoch 10]======================\n",
      " 117/117epoch : [ 10/100] train_loss: 0.02450 valid_loss: 0.02600\n",
      "EarlyStopping counter: 5 out of 20\n",
      "======================[Epoch 11]======================\n",
      " 117/117epoch : [ 11/100] train_loss: 0.02414 valid_loss: 0.02186\n",
      "Validation loss decreased (0.025176 --> 0.021860).  Saving model ...\n",
      "======================[Epoch 12]======================\n",
      " 117/117epoch : [ 12/100] train_loss: 0.02111 valid_loss: 0.02333\n",
      "EarlyStopping counter: 1 out of 20\n",
      "======================[Epoch 13]======================\n",
      " 117/117epoch : [ 13/100] train_loss: 0.02451 valid_loss: 0.02134\n",
      "Validation loss decreased (0.021860 --> 0.021339).  Saving model ...\n",
      "======================[Epoch 14]======================\n",
      " 117/117epoch : [ 14/100] train_loss: 0.02346 valid_loss: 0.02421\n",
      "EarlyStopping counter: 1 out of 20\n",
      "======================[Epoch 15]======================\n",
      " 117/117epoch : [ 15/100] train_loss: 0.01912 valid_loss: 0.02359\n",
      "EarlyStopping counter: 2 out of 20\n",
      "======================[Epoch 16]======================\n",
      " 117/117epoch : [ 16/100] train_loss: 0.02311 valid_loss: 0.02533\n",
      "EarlyStopping counter: 3 out of 20\n",
      "======================[Epoch 17]======================\n",
      " 117/117epoch : [ 17/100] train_loss: 0.01997 valid_loss: 0.02203\n",
      "EarlyStopping counter: 4 out of 20\n",
      "======================[Epoch 18]======================\n",
      " 117/117epoch : [ 18/100] train_loss: 0.02431 valid_loss: 0.02737\n",
      "EarlyStopping counter: 5 out of 20\n",
      "======================[Epoch 19]======================\n",
      " 117/117epoch : [ 19/100] train_loss: 0.02137 valid_loss: 0.02294\n",
      "EarlyStopping counter: 6 out of 20\n",
      "======================[Epoch 20]======================\n",
      " 117/117epoch : [ 20/100] train_loss: 0.01897 valid_loss: 0.02676\n",
      "EarlyStopping counter: 7 out of 20\n",
      "======================[Epoch 21]======================\n",
      " 117/117epoch : [ 21/100] train_loss: 0.01876 valid_loss: 0.02027\n",
      "Validation loss decreased (0.021339 --> 0.020266).  Saving model ...\n",
      "======================[Epoch 22]======================\n",
      " 117/117epoch : [ 22/100] train_loss: 0.01674 valid_loss: 0.02126\n",
      "EarlyStopping counter: 1 out of 20\n",
      "======================[Epoch 23]======================\n",
      " 117/117epoch : [ 23/100] train_loss: 0.02036 valid_loss: 0.01956\n",
      "Validation loss decreased (0.020266 --> 0.019564).  Saving model ...\n",
      "======================[Epoch 24]======================\n",
      " 117/117epoch : [ 24/100] train_loss: 0.01930 valid_loss: 0.01981\n",
      "EarlyStopping counter: 1 out of 20\n",
      "======================[Epoch 25]======================\n",
      " 117/117epoch : [ 25/100] train_loss: 0.01777 valid_loss: 0.02194\n",
      "EarlyStopping counter: 2 out of 20\n",
      "======================[Epoch 26]======================\n",
      " 117/117epoch : [ 26/100] train_loss: 0.01687 valid_loss: 0.02271\n",
      "EarlyStopping counter: 3 out of 20\n",
      "======================[Epoch 27]======================\n",
      " 117/117epoch : [ 27/100] train_loss: 0.01782 valid_loss: 0.02305\n",
      "EarlyStopping counter: 4 out of 20\n",
      "======================[Epoch 28]======================\n",
      " 117/117epoch : [ 28/100] train_loss: 0.02267 valid_loss: 0.03236\n",
      "EarlyStopping counter: 5 out of 20\n",
      "======================[Epoch 29]======================\n",
      " 117/117epoch : [ 29/100] train_loss: 0.02323 valid_loss: 0.02700\n",
      "EarlyStopping counter: 6 out of 20\n",
      "======================[Epoch 30]======================\n",
      " 117/117epoch : [ 30/100] train_loss: 0.01603 valid_loss: 0.02217\n",
      "EarlyStopping counter: 7 out of 20\n",
      "======================[Epoch 31]======================\n",
      " 117/117epoch : [ 31/100] train_loss: 0.02009 valid_loss: 0.02413\n",
      "EarlyStopping counter: 8 out of 20\n",
      "======================[Epoch 32]======================\n",
      " 117/117epoch : [ 32/100] train_loss: 0.01726 valid_loss: 0.02465\n",
      "EarlyStopping counter: 9 out of 20\n",
      "======================[Epoch 33]======================\n",
      " 117/117epoch : [ 33/100] train_loss: 0.01363 valid_loss: 0.02078\n",
      "EarlyStopping counter: 10 out of 20\n",
      "======================[Epoch 34]======================\n",
      " 117/117epoch : [ 34/100] train_loss: 0.01467 valid_loss: 0.02072\n",
      "EarlyStopping counter: 11 out of 20\n",
      "======================[Epoch 35]======================\n",
      " 117/117epoch : [ 35/100] train_loss: 0.01482 valid_loss: 0.02250\n",
      "EarlyStopping counter: 12 out of 20\n",
      "======================[Epoch 36]======================\n",
      " 117/117epoch : [ 36/100] train_loss: 0.01499 valid_loss: 0.02364\n",
      "EarlyStopping counter: 13 out of 20\n",
      "======================[Epoch 37]======================\n",
      " 117/117epoch : [ 37/100] train_loss: 0.01424 valid_loss: 0.02320\n",
      "EarlyStopping counter: 14 out of 20\n",
      "======================[Epoch 38]======================\n",
      " 117/117epoch : [ 38/100] train_loss: 0.01848 valid_loss: 0.02117\n",
      "EarlyStopping counter: 15 out of 20\n",
      "======================[Epoch 39]======================\n",
      " 117/117epoch : [ 39/100] train_loss: 0.02036 valid_loss: 0.02814\n",
      "EarlyStopping counter: 16 out of 20\n",
      "======================[Epoch 40]======================\n",
      " 117/117epoch : [ 40/100] train_loss: 0.01730 valid_loss: 0.02317\n",
      "EarlyStopping counter: 17 out of 20\n",
      "======================[Epoch 41]======================\n",
      " 117/117epoch : [ 41/100] train_loss: 0.02022 valid_loss: 0.02109\n",
      "EarlyStopping counter: 18 out of 20\n",
      "======================[Epoch 42]======================\n",
      " 117/117epoch : [ 42/100] train_loss: 0.02186 valid_loss: 0.02971\n",
      "EarlyStopping counter: 19 out of 20\n",
      "======================[Epoch 43]======================\n",
      " 117/117epoch : [ 43/100] train_loss: 0.02009 valid_loss: 0.02524\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "model, train_loss, valid_loss = train_model(model, batch_size, patience, n_epochs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validation dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test 함수 정의\n",
    "def test1():\n",
    "    \n",
    "    # 추론모드로 전환\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    # 데이터로더에서 미니배치를 하나씩 꺼내 추론을 수행\n",
    "    with torch.no_grad():  # 추론 과정에는 미분이 필요없음\n",
    "        for data, targets in loader_train:\n",
    "\n",
    "            outputs = model(data)\n",
    "            # 추론 계산\n",
    "            _, predicted = torch.max(outputs.data, 1)  # 확률이 가장 높은 레이블이 무엇인지 계산\n",
    "            correct += predicted.eq(targets.data.view_as(predicted)).sum()  # 정답과 일치한 경우 정답 카운트를 증가\n",
    "       \n",
    "    # 정확도 출력\n",
    "    data_num = len(loader_train.dataset)*0.7  # 데이터 총 건수\n",
    "    print('\\ntrain 데이터에서 예측 정확도: {}/{} ({:.0f}%)\\n'.format(correct,\n",
    "                                                   data_num, 100. * correct / data_num)) \n",
    "    \n",
    "\n",
    "# test 함수 정의 \n",
    "def test2():\n",
    "    \n",
    "    # 추론모드로 전환\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    # 데이터로더에서 미니배치를 하나씩 꺼내 추론을 수행\n",
    "    with torch.no_grad():  # 추론 과정에는 미분이 필요없음\n",
    "        for data, targets in loader_valid:\n",
    "\n",
    "            outputs = model(data)\n",
    "            # 추론 계산\n",
    "            _, predicted = torch.max(outputs.data, 1)  # 확률이 가장 높은 레이블이 무엇인지 계산\n",
    "            correct += predicted.eq(targets.data.view_as(predicted)).sum()  # 정답과 일치한 경우 정답 카운트를 증가\n",
    "    # 정확도 출력\n",
    "    data_num = len(loader_train.dataset)*0.3  # 데이터 총 건수\n",
    "    print('\\nvalid 데이터에서 예측 정확도: {}/{} ({:.0f}%)\\n'.format(correct,\n",
    "                                                   data_num, 100. * correct / data_num)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train 데이터에서 예측 정확도: 14867/14902.999999999998 (100%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid 데이터에서 예측 정확도: 6346/6387.0 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_accus)\n",
    "plt.plot(valid_accus)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['Train','Valid'])\n",
    "plt.title('Train vs Valid Accuracy')\n",
    " \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accus = []\n",
    "def test3():\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    model.eval()  # 신경망을 추론 모드로 전환\n",
    "    correct = 0\n",
    "    predicted_total=np.array([0]);\n",
    "    targets_total=np.array([0]);\n",
    "    # 데이터로더에서 미니배치를 하나씩 꺼내 추론을 수행\n",
    "    with torch.no_grad():  # 추론 과정에는 미분이 필요없음\n",
    "        for data, targets in loader_test:\n",
    "\n",
    "            outputs = model(data)  # 데이터를 입력하고 출력을 계산\n",
    "\n",
    "            # 추론 계산\n",
    "            _, predicted = torch.max(outputs.data, 1)  # 확률이 가장 높은 레이블이 무엇인지 계산\n",
    "            correct += predicted.eq(targets.data.view_as(predicted)).sum()# 정답과 일치한 경우 정답 카운트를 증가\n",
    "            predicted=predicted.numpy()\n",
    "            predicted=np.reshape(predicted,(-1,1))\n",
    "            targets=targets.numpy()\n",
    "            targets=np.reshape(targets,(-1,1))\n",
    "            predicted_total=np.vstack((predicted_total,predicted));\n",
    "            targets_total=np.vstack((targets_total,targets));\n",
    "            predicted_total=predicted_total[1:,:];\n",
    "            targets_total=targets_total[1:,:];\n",
    "            cf = confusion_matrix(targets, predicted)\n",
    "\n",
    "    # 정확도 출력\n",
    "    data_num = len(loader_test.dataset)  # 데이터 총 건수\n",
    "    cf = confusion_matrix(targets_total, predicted_total)\n",
    "    print('\\ntest 데이터에서 예측 정확도: {}/{} ({:.0f}%)\\n'.format(correct,\n",
    "                                                   data_num, 100. * correct / data_num))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(cf)\n",
    "    print(\"--------------------------------------------------\")\n",
    "    return targets_total, predicted_total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test 데이터에서 예측 정확도: 7056/7097 (99%)\n",
      "\n",
      "--------------------------------------------------\n",
      "[[  41   13   16    0]\n",
      " [   8  359    0    0]\n",
      " [   4    0 5992    0]\n",
      " [   0    0    0  609]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1],\n",
       "        [2],\n",
       "        [2],\n",
       "        ...,\n",
       "        [3],\n",
       "        [2],\n",
       "        [2]], dtype=int64),\n",
       " array([[1],\n",
       "        [2],\n",
       "        [2],\n",
       "        ...,\n",
       "        [3],\n",
       "        [2],\n",
       "        [2]], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
